{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AthleticsDataScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = 'https://www.alltime-athletics.com/'\n",
    "    \n",
    "    def generate_url(self, event, is_legal):\n",
    "        # Handle special cases with different URL patterns\n",
    "        special_cases = {\n",
    "            '100m': ('m_100ok.htm', 'm100mno.htm'),\n",
    "            'trip': ('mtripok.htm', 'mtripno.htm'),\n",
    "            'long': ('mlongok.htm', 'mlongno.htm'),\n",
    "            '110h': ('m_110hok.htm', 'm_110hno.htm'),\n",
    "            'pole': ('mpoleok.htm','mpoleno.htm'),\n",
    "            'shot': ('mshotok.htm','mshotno.htm'),\n",
    "            'disc': ('mdiscok.htm','mdiscno.htm'),\n",
    "            'jave': ('mjaveok.htm','mjaveno.htm'),\n",
    "            'hamm': ('mhammok.htm','mhammno.htm'),\n",
    "            'deca': ('mdecaok.htm','mdecano.htm'),\n",
    "            '60m':   ('m60mok.htm','m60mno.htm')\n",
    "            # Add more special cases here if needed\n",
    "        }\n",
    "        if event in special_cases:\n",
    "            legal_suffix, illegal_suffix = special_cases[event]\n",
    "            suffix = legal_suffix if is_legal else illegal_suffix\n",
    "        else:\n",
    "            suffix = f\"m_{event}{'ok' if is_legal else 'no'}.htm\"\n",
    "        \n",
    "        return f\"{self.base_url}{suffix}\"\n",
    "    \n",
    "    def fetch_data(self, event, is_legal):\n",
    "        url = self.generate_url(event, is_legal)\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pre_tag = soup.find('pre')\n",
    "        table_text = pre_tag.get_text()\n",
    "        rows = table_text.split('\\n')\n",
    "\n",
    "        def process_row(row):\n",
    "            parts = re.split(r'\\s{2,}', row)\n",
    "            return [part.strip() for part in parts]\n",
    "\n",
    "        data = []\n",
    "        max_length = 0\n",
    "        for row in rows:\n",
    "            if row.strip():\n",
    "                processed_row = process_row(row)\n",
    "                data.append(processed_row)\n",
    "                max_length = max(max_length, len(processed_row))\n",
    "\n",
    "        # Define column names based on the maximum row length\n",
    "        if max_length == 10:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\", \"Wind\", \"Name\", \"Country\", \"DOB\", \"Position_in_race\", \"City\", \"Date\"]\n",
    "        else:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\", \"Name\", \"Country\", \"DOB\", \"Position_in_race\", \"City\", \"Date\"]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=column_names[:max_length])\n",
    "        df.drop('Test', inplace=True, axis=1, errors='ignore')\n",
    "        df['Legal'] = 'Y' if is_legal else 'N'\n",
    "        has_wind = 'Wind' in df.columns\n",
    "        return df, has_wind\n",
    "    \n",
    "    def add_all_conditions_rank(self, df, event):\n",
    "        if re.search(r'\\d', event):\n",
    "            # This is a race event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(method='min')\n",
    "        else:\n",
    "            # This is a field event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(ascending=False, method='min')\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def add_age_at_time_of_race(self, df):\n",
    "        # Convert DOB and Date columns to datetime with the correct format\n",
    "        df['DOB'] = pd.to_datetime(df['DOB'], format='%d.%m.%Y', errors='coerce')\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y', errors='coerce')\n",
    "    \n",
    "        # Correct misinterpreted dates\n",
    "        df['DOB'] = df['DOB'].apply(lambda x: x if pd.isnull(x) or x.year < 2023 else pd.Timestamp(year=x.year - 100, month=x.month, day=x.day))\n",
    "    \n",
    "        # Calculate age at the time of race\n",
    "        df['Age at Time of Race'] = df.apply(lambda row: row['Date'].year - row['DOB'].year - \n",
    "                                             ((row['Date'].month, row['Date'].day) < (row['DOB'].month, row['DOB'].day)) if pd.notnull(row['DOB']) else pd.NA, axis=1)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def add_competition_id(self, df):\n",
    "        # Ensure 'Date' is formatted correctly\n",
    "        df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Create a concatenated string of Date and City\n",
    "        df['competition_id'] = df.apply(lambda row: f\"{row['Date']}_{row['City']}\", axis=1)\n",
    "\n",
    "        # Hash the concatenated string to create a unique ID\n",
    "        df['competition_id'] = df['competition_id'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "\n",
    "    def get_combined_data(self, event):\n",
    "        df_legal, has_wind = self.fetch_data(event, True)\n",
    "\n",
    "        if has_wind:\n",
    "            df_illegal, _ = self.fetch_data(event, False)\n",
    "            df_combined = pd.concat([df_legal, df_illegal], ignore_index=True)\n",
    "        else:\n",
    "            df_combined = df_legal\n",
    "\n",
    "        df_combined.dropna(inplace=True)\n",
    "        df_combined['Date'] = pd.to_datetime(df_combined['Date'], format='%d.%m.%Y')\n",
    "        df_combined['DOB'] = pd.to_datetime(df_combined['DOB'], format='%d.%m.%y', errors='coerce')\n",
    "\n",
    "\n",
    "        # Extract any letters and '#' from the 'Time' column and put them into a new 'Note' column\n",
    "        df_combined['Note'] = df_combined['Time'].str.extract(r'([a-zA-Z#*@+´]+)', expand=False)\n",
    "        # Remove the letters and '#' from the 'Time' column\n",
    "        df_combined['Time'] = df_combined['Time'].str.replace(r'[a-zA-Z#*@+´]', '', regex=True)\n",
    "        df_combined['Time'] = df_combined['Time'].astype('float')\n",
    "        df_combined['Sex'] = 'Male'\n",
    "        df_combined['Event'] = event\n",
    "        df_combined = self.add_all_conditions_rank(df_combined, event)\n",
    "\n",
    "        df_combined.loc[df_combined['Legal'] == 'N', 'Rank'] = pd.NA\n",
    "        df_combined = self.add_age_at_time_of_race(df_combined)\n",
    "\n",
    "        df_combined = self.add_competition_id(df_combined)\n",
    "\n",
    "\n",
    "        return df_combined\n",
    "\n",
    "\n",
    "scraper = AthleticsDataScraper()\n",
    "df_200m = scraper.get_combined_data('200')\n",
    "df_100m = scraper.get_combined_data('100m')\n",
    "df_400m = scraper.get_combined_data('400')\n",
    "df_long = scraper.get_combined_data('long')\n",
    "df_trip = scraper.get_combined_data('trip')\n",
    "df_110h = scraper.get_combined_data('110h')\n",
    "df_400h = scraper.get_combined_data('400h')\n",
    "df_pole = scraper.get_combined_data('pole')\n",
    "df_shot = scraper.get_combined_data('shot')\n",
    "df_disc = scraper.get_combined_data('disc')\n",
    "df_jave = scraper.get_combined_data('jave')\n",
    "df_hamm = scraper.get_combined_data('hamm')\n",
    "df_deca = scraper.get_combined_data('deca')\n",
    "df_60m = scraper.get_combined_data('60m')\n",
    "df_300m = scraper.get_combined_data('300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AthleticsDataScraper_w:\n",
    "    def __init__(self):\n",
    "        self.base_url = 'https://www.alltime-athletics.com/'\n",
    "    \n",
    "    def generate_url(self, event, is_legal):\n",
    "        # Handle special cases with different URL patterns\n",
    "        special_cases = {\n",
    "            '100m': ('w_100ok.htm', 'w_100no.htm'),\n",
    "            'trip': ('wtripleok.htm', 'wtripleno.htm'),\n",
    "            'long': ('wlongok.htm', 'wlongno.htm'),\n",
    "            '100h': ('w_100hok.htm', 'w_100hno.htm'),\n",
    "            'pole': ('wpoleok.htm','wpoleno.htm'),\n",
    "            'shot': ('wshotok.htm','wshotno.htm'),\n",
    "            'disc': ('wdiscok.htm','wdiscno.htm'),\n",
    "            'jave': ('wjaveok.htm','wjaveno.htm'),\n",
    "            'hamm': ('whammok.htm','whammno.htm'),\n",
    "            'hept': ('whepaok.htm','wheptno.htm'),\n",
    "            '60m':   ('w60mok.htm','w60mno.htm')\n",
    "            # Add more special cases here if needed\n",
    "        }\n",
    "        if event in special_cases:\n",
    "            legal_suffix, illegal_suffix = special_cases[event]\n",
    "            suffix = legal_suffix if is_legal else illegal_suffix\n",
    "        else:\n",
    "            suffix = f\"w_{event}{'ok' if is_legal else 'no'}.htm\"\n",
    "        \n",
    "        return f\"{self.base_url}{suffix}\"\n",
    "    \n",
    "    def fetch_data(self, event, is_legal):\n",
    "        url = self.generate_url(event, is_legal)\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pre_tag = soup.find('pre')\n",
    "        table_text = pre_tag.get_text()\n",
    "        rows = table_text.split('\\n')\n",
    "\n",
    "        def process_row(row):\n",
    "            parts = re.split(r'\\s{2,}', row)\n",
    "            return [part.strip() for part in parts]\n",
    "\n",
    "        data = []\n",
    "        max_length = 0\n",
    "        for row in rows:\n",
    "            if row.strip():\n",
    "                processed_row = process_row(row)\n",
    "                data.append(processed_row)\n",
    "                max_length = max(max_length, len(processed_row))\n",
    "\n",
    "        # Define column names based on the maximum row length\n",
    "        if max_length == 10:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\", \"Wind\", \"Name\", \"Country\", \"DOB\", \"Position_in_race\", \"City\", \"Date\"]\n",
    "        else:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\", \"Name\", \"Country\", \"DOB\", \"Position_in_race\", \"City\", \"Date\"]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=column_names[:max_length])\n",
    "        df.drop('Test', inplace=True, axis=1, errors='ignore')\n",
    "        df['Legal'] = 'Y' if is_legal else 'N'\n",
    "        has_wind = 'Wind' in df.columns\n",
    "        return df, has_wind\n",
    "    \n",
    "    def add_all_conditions_rank(self, df, event):\n",
    "        if re.search(r'\\d', event):\n",
    "            # This is a race event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(method='min')\n",
    "        else:\n",
    "            # This is a field event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(ascending=False, method='min')\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def add_age_at_time_of_race(self, df):\n",
    "        # Convert DOB and Date columns to datetime with the correct format\n",
    "        df['DOB'] = pd.to_datetime(df['DOB'], format='%d.%m.%Y', errors='coerce')\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y', errors='coerce')\n",
    "    \n",
    "        # Correct misinterpreted dates\n",
    "        df['DOB'] = df['DOB'].apply(lambda x: x if pd.isnull(x) or x.year < 2023 else pd.Timestamp(year=x.year - 100, month=x.month, day=x.day))\n",
    "    \n",
    "        # Calculate age at the time of race\n",
    "        df['Age at Time of Race'] = df.apply(lambda row: row['Date'].year - row['DOB'].year - \n",
    "                                             ((row['Date'].month, row['Date'].day) < (row['DOB'].month, row['DOB'].day)) if pd.notnull(row['DOB']) else pd.NA, axis=1)\n",
    "    \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    def add_competition_id(self, df):\n",
    "        # Ensure 'Date' is formatted correctly\n",
    "        df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Create a concatenated string of Date and City\n",
    "        df['competition_id'] = df.apply(lambda row: f\"{row['Date']}_{row['City']}\", axis=1)\n",
    "\n",
    "        # Hash the concatenated string to create a unique ID\n",
    "        df['competition_id'] = df['competition_id'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "\n",
    "    def get_combined_data(self, event):\n",
    "        df_legal, has_wind = self.fetch_data(event, True)\n",
    "\n",
    "        if has_wind:\n",
    "            df_illegal, _ = self.fetch_data(event, False)\n",
    "            df_combined = pd.concat([df_legal, df_illegal], ignore_index=True)\n",
    "        else:\n",
    "            df_combined = df_legal\n",
    "\n",
    "        df_combined.dropna(inplace=True)\n",
    "        df_combined['Date'] = pd.to_datetime(df_combined['Date'], format='%d.%m.%Y',errors='coerce')\n",
    "        df_combined['DOB'] = pd.to_datetime(df_combined['DOB'], format='%d.%m.%y', errors='coerce')\n",
    "\n",
    "\n",
    "        # Extract any letters and '#' from the 'Time' column and put them into a new 'Note' column\n",
    "        df_combined['Note'] = df_combined['Time'].str.extract(r'([a-zA-Z#*@+´]+)', expand=False)\n",
    "        # Remove the letters and '#' from the 'Time' column\n",
    "        df_combined['Time'] = df_combined['Time'].str.replace(r'[a-zA-Z#*@+´]', '', regex=True)\n",
    "\n",
    "        df_combined['Time'] = df_combined['Time'].astype('float')\n",
    "        df_combined = self.add_all_conditions_rank(df_combined, event)\n",
    "\n",
    "        df_combined.loc[df_combined['Legal'] == 'N', 'Rank'] = pd.NA\n",
    "        df_combined = self.add_age_at_time_of_race(df_combined)\n",
    "        df_combined['Sex'] = 'Female'\n",
    "        df_combined['Event'] = event\n",
    "        df_combined = self.add_competition_id(df_combined)\n",
    "\n",
    "\n",
    "        return df_combined\n",
    "\n",
    "\n",
    "scraper = AthleticsDataScraper_w()\n",
    "df_200m_w = scraper.get_combined_data('200')\n",
    "df_100m_w = scraper.get_combined_data('100m')\n",
    "df_400m_w = scraper.get_combined_data('400')\n",
    "df_long_w = scraper.get_combined_data('long')\n",
    "df_trip_w = scraper.get_combined_data('trip')\n",
    "df_100h_w = scraper.get_combined_data('100h')\n",
    "df_400h_w = scraper.get_combined_data('400h')\n",
    "df_pole_w = scraper.get_combined_data('pole')\n",
    "df_shot_w = scraper.get_combined_data('shot')\n",
    "df_disc_w = scraper.get_combined_data('disc')\n",
    "df_jave_w = scraper.get_combined_data('jave')\n",
    "df_hamm_w = scraper.get_combined_data('hamm')\n",
    "df_hept_w = scraper.get_combined_data('hept')\n",
    "df_60m_w = scraper.get_combined_data('60m')\n",
    "df_300m_w = scraper.get_combined_data('300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_women = [df_200m_w, df_100m_w, df_400m_w, df_long_w, df_trip_w, df_100h_w, df_400h_w, df_pole_w, df_shot_w, df_disc_w, df_jave_w, df_hamm_w, df_hept_w, df_60m_w, df_300m_w]\n",
    "combined_women = pd.concat(dfs_women, ignore_index=True)\n",
    "\n",
    "# Combine all men's dataframes\n",
    "dfs_men = [df_200m, df_100m, df_400m, df_long, df_trip, df_110h, df_400h, df_pole, df_shot, df_disc, df_jave, df_hamm, df_deca, df_60m, df_300m]\n",
    "combined_men = pd.concat(dfs_men, ignore_index=True)\n",
    "\n",
    "# Ensure the 'Wind' column is present in all dataframes\n",
    "if 'Wind' not in combined_women.columns:\n",
    "    combined_women['Wind'] = pd.NA\n",
    "if 'Wind' not in combined_men.columns:\n",
    "    combined_men['Wind'] = pd.NA\n",
    "\n",
    "# Combine women's and men's dataframes\n",
    "combined_all = pd.concat([combined_women, combined_men], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Time</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Position_in_race</th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>Legal</th>\n",
       "      <th>Note</th>\n",
       "      <th>All Conditions Rank</th>\n",
       "      <th>Age at Time of Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Event</th>\n",
       "      <th>competition_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21.34</td>\n",
       "      <td>+1.3</td>\n",
       "      <td>Florence Griffith-Joyner</td>\n",
       "      <td>USA</td>\n",
       "      <td>1959-12-21</td>\n",
       "      <td>1</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>1988-09-29</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>200</td>\n",
       "      <td>457294ca525d32c99efe07c6c4bc06c44b631fbb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21.41</td>\n",
       "      <td>+0.1</td>\n",
       "      <td>Shericka Jackson</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1994-07-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Budapest</td>\n",
       "      <td>2023-08-25</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>200</td>\n",
       "      <td>bfac2418455160c83a85740206a7e756f7908d07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>21.45</td>\n",
       "      <td>+0.6</td>\n",
       "      <td>Shericka Jackson</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1994-07-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Eugene</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>200</td>\n",
       "      <td>dc98c5290c6154aab880c72e64f6d6e076d2da3f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21.48</td>\n",
       "      <td>+0.2</td>\n",
       "      <td>Shericka Jackson</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1994-07-16</td>\n",
       "      <td>1</td>\n",
       "      <td>Bruxelles</td>\n",
       "      <td>2023-09-08</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>200</td>\n",
       "      <td>c8214a1fc1bcd9d9ac9b1c9f3ea49b4a8ff31ba3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>21.53</td>\n",
       "      <td>+0.8</td>\n",
       "      <td>Elaine Thompson-Herah</td>\n",
       "      <td>JAM</td>\n",
       "      <td>1992-06-28</td>\n",
       "      <td>1</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>200</td>\n",
       "      <td>35d526797ba44571a435009202a8f8788b4f99c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85491</th>\n",
       "      <td>557</td>\n",
       "      <td>32.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Manteo Mitchell</td>\n",
       "      <td>USA</td>\n",
       "      <td>1987-07-06</td>\n",
       "      <td>6</td>\n",
       "      <td>Naimette-Xhovémont</td>\n",
       "      <td>2015-07-15</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>300</td>\n",
       "      <td>f6df05cb8c015e96586e09a92a6b49e80827bd7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85492</th>\n",
       "      <td>557</td>\n",
       "      <td>32.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan Jirka</td>\n",
       "      <td>CZE</td>\n",
       "      <td>1993-10-05</td>\n",
       "      <td>1r1</td>\n",
       "      <td>Praha</td>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Male</td>\n",
       "      <td>300</td>\n",
       "      <td>694030d64dd74f0edab2ac42be5296a7afaf1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85493</th>\n",
       "      <td>557</td>\n",
       "      <td>32.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Keenan Blake</td>\n",
       "      <td>NED</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>1rB</td>\n",
       "      <td>Lisse</td>\n",
       "      <td>2023-05-13</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>300</td>\n",
       "      <td>68879804699b4c55eee3d73c1f1b0ccd986e4941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85494</th>\n",
       "      <td>557</td>\n",
       "      <td>32.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samuel García</td>\n",
       "      <td>ESP</td>\n",
       "      <td>1991-12-04</td>\n",
       "      <td>2r2</td>\n",
       "      <td>Pliezhausen</td>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>31</td>\n",
       "      <td>Male</td>\n",
       "      <td>300</td>\n",
       "      <td>bf17ba857d6256de123e75552f1a098ee552b5e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85495</th>\n",
       "      <td>557</td>\n",
       "      <td>32.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruo Ekejunia</td>\n",
       "      <td>JPN</td>\n",
       "      <td>2004-12-14</td>\n",
       "      <td>1h3</td>\n",
       "      <td>Kagoshima</td>\n",
       "      <td>2023-10-14</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>18</td>\n",
       "      <td>Male</td>\n",
       "      <td>300</td>\n",
       "      <td>20aeb59c07da841549c590609d6e29c22afef624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85496 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rank   Time  Wind                      Name Country        DOB  \\\n",
       "0        1  21.34  +1.3  Florence Griffith-Joyner     USA 1959-12-21   \n",
       "1        2  21.41  +0.1          Shericka Jackson     JAM 1994-07-16   \n",
       "2        3  21.45  +0.6          Shericka Jackson     JAM 1994-07-16   \n",
       "3        4  21.48  +0.2          Shericka Jackson     JAM 1994-07-16   \n",
       "4        5  21.53  +0.8     Elaine Thompson-Herah     JAM 1992-06-28   \n",
       "...    ...    ...   ...                       ...     ...        ...   \n",
       "85491  557  32.99   NaN           Manteo Mitchell     USA 1987-07-06   \n",
       "85492  557  32.99   NaN                 Jan Jirka     CZE 1993-10-05   \n",
       "85493  557  32.99   NaN              Keenan Blake     NED 2003-01-01   \n",
       "85494  557  32.99   NaN             Samuel García     ESP 1991-12-04   \n",
       "85495  557  32.99   NaN              Ruo Ekejunia     JPN 2004-12-14   \n",
       "\n",
       "      Position_in_race                City        Date Legal Note  \\\n",
       "0                    1               Seoul  1988-09-29     Y  NaN   \n",
       "1                    1            Budapest  2023-08-25     Y  NaN   \n",
       "2                    1              Eugene  2022-07-21     Y  NaN   \n",
       "3                    1           Bruxelles  2023-09-08     Y  NaN   \n",
       "4                    1               Tokyo  2021-08-03     Y  NaN   \n",
       "...                ...                 ...         ...   ...  ...   \n",
       "85491                6  Naimette-Xhovémont  2015-07-15     Y  NaN   \n",
       "85492              1r1               Praha  2017-05-06     Y  NaN   \n",
       "85493              1rB               Lisse  2023-05-13     Y  NaN   \n",
       "85494              2r2         Pliezhausen  2023-05-14     Y  NaN   \n",
       "85495              1h3           Kagoshima  2023-10-14     Y  NaN   \n",
       "\n",
       "       All Conditions Rank Age at Time of Race     Sex Event  \\\n",
       "0                      1.0                  28  Female   200   \n",
       "1                      2.0                  29  Female   200   \n",
       "2                      3.0                  28  Female   200   \n",
       "3                      4.0                  29  Female   200   \n",
       "4                      5.0                  29  Female   200   \n",
       "...                    ...                 ...     ...   ...   \n",
       "85491                555.0                  28    Male   300   \n",
       "85492                555.0                  23    Male   300   \n",
       "85493                555.0                  20    Male   300   \n",
       "85494                555.0                  31    Male   300   \n",
       "85495                555.0                  18    Male   300   \n",
       "\n",
       "                                 competition_id  \n",
       "0      457294ca525d32c99efe07c6c4bc06c44b631fbb  \n",
       "1      bfac2418455160c83a85740206a7e756f7908d07  \n",
       "2      dc98c5290c6154aab880c72e64f6d6e076d2da3f  \n",
       "3      c8214a1fc1bcd9d9ac9b1c9f3ea49b4a8ff31ba3  \n",
       "4      35d526797ba44571a435009202a8f8788b4f99c9  \n",
       "...                                         ...  \n",
       "85491  f6df05cb8c015e96586e09a92a6b49e80827bd7d  \n",
       "85492  694030d64dd74f0edab2ac42be5296a7afaf1603  \n",
       "85493  68879804699b4c55eee3d73c1f1b0ccd986e4941  \n",
       "85494  bf17ba857d6256de123e75552f1a098ee552b5e9  \n",
       "85495  20aeb59c07da841549c590609d6e29c22afef624  \n",
       "\n",
       "[85496 rows x 16 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
