{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AthleticsDataScraper:\n",
    "    def __init__(self):\n",
    "        self.base_url = 'https://www.alltime-athletics.com/'\n",
    "    \n",
    "    def generate_url(self, event, is_legal):\n",
    "        # Handle special cases with different URL patterns\n",
    "        special_cases = {\n",
    "            '100m': ('m_100ok.htm', 'm100mno.htm'),\n",
    "            'trip': ('mtripok.htm', 'mtripno.htm'),\n",
    "            'long': ('mlongok.htm', 'mlongno.htm'),\n",
    "            '110h': ('m_110hok.htm', 'm_110hno.htm'),\n",
    "            'pole': ('mpoleok.htm','mpoleno.htm'),\n",
    "            'shot': ('mshotok.htm','mshotno.htm'),\n",
    "            'disc': ('mdiscok.htm','mdiscno.htm'),\n",
    "            'jave': ('mjaveok.htm','mjaveno.htm'),\n",
    "            'hamm': ('mhammok.htm','mhammno.htm'),\n",
    "            'deca': ('mdecaok.htm','mdecano.htm'),\n",
    "            '60m':   ('m60mok.htm','m60mno.htm'),\n",
    "            '800m':   ('m_800ok.htm','m_800no.htm'),\n",
    "            '1500m': ('m_1500ok.htm','m_1500no.htm'),\n",
    "            '5000m':   ('m_5000ok.htm','m_5000no.htm'),\n",
    "            '10000':   ('m_10kok.htm','10kno.htm')\n",
    "            # Add more special cases here if needed\n",
    "        }\n",
    "        if event in special_cases:\n",
    "            legal_suffix, illegal_suffix = special_cases[event]\n",
    "            suffix = legal_suffix if is_legal else illegal_suffix\n",
    "        else:\n",
    "            suffix = f\"m_{event}{'ok' if is_legal else 'no'}.htm\"\n",
    "        \n",
    "        return f\"{self.base_url}{suffix}\"\n",
    "\n",
    "    def convert_mmss_to_seconds(self, time_str):\n",
    "        parts = time_str.split(':')\n",
    "        if len(parts) == 2:\n",
    "            minutes = int(parts[0])\n",
    "            seconds = float(parts[1])\n",
    "            return minutes * 60 + seconds\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    def fetch_data(self, event, is_legal):\n",
    "        url = self.generate_url(event, is_legal)\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pre_tag = soup.find('pre')\n",
    "        table_text = pre_tag.get_text()\n",
    "        rows = table_text.split('\\n')\n",
    "\n",
    "        def process_row(row):\n",
    "            parts = re.split(r'\\s{2,}', row)\n",
    "            return [part.strip() for part in parts]\n",
    "\n",
    "        data = []\n",
    "        max_length = 0\n",
    "        for row in rows:\n",
    "            if row.strip():\n",
    "                processed_row = process_row(row)\n",
    "                data.append(processed_row)\n",
    "                max_length = max(max_length, len(processed_row))\n",
    "\n",
    "        # Define column names based on the maximum row length\n",
    "        if max_length == 10:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\", \"Wind\", \"Name\", \"Country\", \"DOB\", \"Position_in_race\", \"City\", \"Date\"]\n",
    "        else:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\", \"Name\", \"Country\", \"DOB\", \"Position_in_race\", \"City\", \"Date\"]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=column_names[:max_length])\n",
    "        df.drop('Test', inplace=True, axis=1, errors='ignore')\n",
    "        df['Legal'] = 'Y' if is_legal else 'N'\n",
    "        has_wind = 'Wind' in df.columns\n",
    "        return df, has_wind\n",
    "    \n",
    "    def add_all_conditions_rank(self, df, event):\n",
    "        if re.search(r'\\d', event):\n",
    "            # This is a race event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(method='min')\n",
    "        else:\n",
    "            # This is a field event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(ascending=False, method='min')\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def add_age_at_time_of_race(self, df):\n",
    "        # Convert DOB and Date columns to datetime with the correct format\n",
    "        df['DOB'] = pd.to_datetime(df['DOB'], format='%d.%m.%Y', errors='coerce')\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y', errors='coerce')\n",
    "    \n",
    "        # Correct misinterpreted dates\n",
    "        df['DOB'] = df['DOB'].apply(lambda x: x if pd.isnull(x) or x.year < 2023 else pd.Timestamp(year=x.year - 100, month=x.month, day=x.day))\n",
    "    \n",
    "        # Calculate age at the time of race\n",
    "        df['Age at Time of Race'] = df.apply(lambda row: row['Date'].year - row['DOB'].year - \n",
    "                                             ((row['Date'].month, row['Date'].day) < (row['DOB'].month, row['DOB'].day)) if pd.notnull(row['DOB']) else pd.NA, axis=1)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def add_competition_id(self, df):\n",
    "        # Ensure 'Date' is formatted correctly\n",
    "        df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Create a concatenated string of Date and City\n",
    "        df['competition_id'] = df.apply(lambda row: f\"{row['Date']}_{row['City']}\", axis=1)\n",
    "\n",
    "        # Hash the concatenated string to create a unique ID\n",
    "        df['competition_id'] = df['competition_id'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fill_mode_dob(self, df):\n",
    "        # Calculate mode DOB for each athlete (Name)\n",
    "        mode_dob = df.groupby('Name')['DOB'].agg(lambda x: x.mode().iat[0] if not x.mode().empty else np.nan).reset_index()\n",
    "        \n",
    "        # Merge mode DOB back into original DataFrame\n",
    "        df = df.merge(mode_dob, on='Name', suffixes=('', '_mode'))\n",
    "        \n",
    "        # Replace DOB with mode DOB where DOB is missing or different from mode DOB\n",
    "        df['DOB'] = df.apply(lambda row: row['DOB_mode'] if pd.isnull(row['DOB']) or row['DOB'] != row['DOB_mode'] else row['DOB'], axis=1)\n",
    "        \n",
    "        # Drop temporary columns\n",
    "        df.drop(columns=['DOB_mode'], inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    \n",
    "\n",
    "    def get_combined_data(self, event):\n",
    "        df_legal, has_wind = self.fetch_data(event, True)\n",
    "\n",
    "        if has_wind:\n",
    "            df_illegal, _ = self.fetch_data(event, False)\n",
    "            df_combined = pd.concat([df_legal, df_illegal], ignore_index=True)\n",
    "        else:\n",
    "            df_combined = df_legal\n",
    "\n",
    "        df_combined.dropna(inplace=True)\n",
    "        df_combined['Date'] = pd.to_datetime(df_combined['Date'], format='%d.%m.%Y')\n",
    "        df_combined['DOB'] = pd.to_datetime(df_combined['DOB'], format='%d.%m.%y', errors='coerce')\n",
    "        df_combined = self.fill_mode_dob(df_combined)\n",
    "\n",
    "        # Extract any letters and '#' from the 'Time' column and put them into a new 'Note' column\n",
    "        df_combined['Note'] = df_combined['Time'].str.extract(r'([a-zA-Z#*@+´]+)', expand=False)\n",
    "        # Remove the letters and '#' from the 'Time' column\n",
    "        df_combined['Time'] = df_combined['Time'].str.replace(r'[a-zA-Z#*@+´]', '', regex=True)\n",
    "        if event in ['800','1500', '5000', '10000']:\n",
    "            df_combined['Time'] = df_combined['Time'].apply(self.convert_mmss_to_seconds)\n",
    "        df_combined['Time'] = df_combined['Time'].astype('float')\n",
    "        df_combined['Sex'] = 'Male'\n",
    "        df_combined['Event'] = event\n",
    "        df_combined = self.add_all_conditions_rank(df_combined, event)\n",
    "\n",
    "        df_combined.loc[df_combined['Legal'] == 'N', 'Rank'] = pd.NA\n",
    "        df_combined = self.add_age_at_time_of_race(df_combined)\n",
    "\n",
    "        df_combined = self.add_competition_id(df_combined)\n",
    "\n",
    "\n",
    "        return df_combined\n",
    "\n",
    "\n",
    "scraper   = AthleticsDataScraper()\n",
    "df_200m   = scraper.get_combined_data('200')\n",
    "df_100m   = scraper.get_combined_data('100m')\n",
    "df_400m   = scraper.get_combined_data('400')\n",
    "df_long   = scraper.get_combined_data('long')\n",
    "df_trip   = scraper.get_combined_data('trip')\n",
    "df_110h   = scraper.get_combined_data('110h')\n",
    "df_400h   = scraper.get_combined_data('400h')\n",
    "df_pole   = scraper.get_combined_data('pole')\n",
    "df_shot   = scraper.get_combined_data('shot')\n",
    "df_disc   = scraper.get_combined_data('disc')\n",
    "df_jave   = scraper.get_combined_data('jave')\n",
    "df_hamm   = scraper.get_combined_data('hamm')\n",
    "df_deca   = scraper.get_combined_data('deca')\n",
    "df_60m    = scraper.get_combined_data('60m')\n",
    "df_300m   = scraper.get_combined_data('300')\n",
    "df_800m   = scraper.get_combined_data('800')\n",
    "df_5000m  = scraper.get_combined_data('5000')\n",
    "df_10000m = scraper.get_combined_data('10000')\n",
    "df_1500m  = scraper.get_combined_data('1500')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Time</th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Position_in_race</th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>Legal</th>\n",
       "      <th>Note</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Event</th>\n",
       "      <th>All Conditions Rank</th>\n",
       "      <th>Age at Time of Race</th>\n",
       "      <th>competition_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1571.00</td>\n",
       "      <td>Joshua Cheptegei</td>\n",
       "      <td>UGA</td>\n",
       "      <td>1996-09-12</td>\n",
       "      <td>1</td>\n",
       "      <td>Valencia</td>\n",
       "      <td>2020-10-07</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0422bfe2cdbecddf856ee41f164e8bf3bc33f38f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>1608.36</td>\n",
       "      <td>Joshua Cheptegei</td>\n",
       "      <td>UGA</td>\n",
       "      <td>1996-09-12</td>\n",
       "      <td>1</td>\n",
       "      <td>Ad-Dawhah</td>\n",
       "      <td>2019-10-06</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>23</td>\n",
       "      <td>39bbc84ed11efeb5bdf814278371fedc2cef5941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>1609.94</td>\n",
       "      <td>Joshua Cheptegei</td>\n",
       "      <td>UGA</td>\n",
       "      <td>1996-09-12</td>\n",
       "      <td>2</td>\n",
       "      <td>London</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20</td>\n",
       "      <td>e4ac5ae5143127a878c03d4999da472502d7eed4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292</td>\n",
       "      <td>1630.06</td>\n",
       "      <td>Joshua Cheptegei</td>\n",
       "      <td>UGA</td>\n",
       "      <td>1996-09-12</td>\n",
       "      <td>6</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>2016-08-13</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>292.0</td>\n",
       "      <td>19</td>\n",
       "      <td>db1932a108766537b9222525868da13b72e1596f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>479</td>\n",
       "      <td>1639.62</td>\n",
       "      <td>Joshua Cheptegei</td>\n",
       "      <td>UGA</td>\n",
       "      <td>1996-09-12</td>\n",
       "      <td>1</td>\n",
       "      <td>Gold Coast</td>\n",
       "      <td>2018-04-13</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>478.0</td>\n",
       "      <td>21</td>\n",
       "      <td>ee749a0b81a3cdfbbd98574af92138f0f7241373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10056</th>\n",
       "      <td>10108</td>\n",
       "      <td>1709.95</td>\n",
       "      <td>Rui Viera</td>\n",
       "      <td>POR</td>\n",
       "      <td>1970-02-04</td>\n",
       "      <td>4rB</td>\n",
       "      <td>Barakaldo</td>\n",
       "      <td>1997-04-05</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>10048.0</td>\n",
       "      <td>27</td>\n",
       "      <td>d505173d07a70fd35ebd17a2f09daa959e071dde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10057</th>\n",
       "      <td>10113</td>\n",
       "      <td>1709.96</td>\n",
       "      <td>Joe Driscoll</td>\n",
       "      <td>USA</td>\n",
       "      <td>1979-11-02</td>\n",
       "      <td>6r2</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>2008-05-04</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>10053.0</td>\n",
       "      <td>28</td>\n",
       "      <td>19e3896b4768cbf1e18a4fc70a61e70c4dbefab1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10058</th>\n",
       "      <td>10115</td>\n",
       "      <td>1709.97</td>\n",
       "      <td>Andrew Garnham</td>\n",
       "      <td>AUS</td>\n",
       "      <td>1960-02-06</td>\n",
       "      <td>9</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>1986-12-18</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>26</td>\n",
       "      <td>334cb4c6aac64fbfe1236661e65a79fe96e672da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10059</th>\n",
       "      <td>10115</td>\n",
       "      <td>1709.97</td>\n",
       "      <td>Aleksandr Burtsev</td>\n",
       "      <td>BLR</td>\n",
       "      <td>1965-02-13</td>\n",
       "      <td>4</td>\n",
       "      <td>Moskva</td>\n",
       "      <td>1990-06-09</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>25</td>\n",
       "      <td>162f22b38cf055e4619f23c494e3358a7ee96ff2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060</th>\n",
       "      <td>10115</td>\n",
       "      <td>1709.97</td>\n",
       "      <td>Junpei Kanisawa</td>\n",
       "      <td>JPN</td>\n",
       "      <td>1995-12-01</td>\n",
       "      <td>4r4</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>2021-10-24</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000</td>\n",
       "      <td>10055.0</td>\n",
       "      <td>25</td>\n",
       "      <td>e1fd79471d342dea26e83901aa715a098075500d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10061 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Rank     Time               Name Country        DOB Position_in_race  \\\n",
       "0          1  1571.00   Joshua Cheptegei     UGA 1996-09-12                1   \n",
       "1         39  1608.36   Joshua Cheptegei     UGA 1996-09-12                1   \n",
       "2         56  1609.94   Joshua Cheptegei     UGA 1996-09-12                2   \n",
       "3        292  1630.06   Joshua Cheptegei     UGA 1996-09-12                6   \n",
       "4        479  1639.62   Joshua Cheptegei     UGA 1996-09-12                1   \n",
       "...      ...      ...                ...     ...        ...              ...   \n",
       "10056  10108  1709.95          Rui Viera     POR 1970-02-04              4rB   \n",
       "10057  10113  1709.96       Joe Driscoll     USA 1979-11-02              6r2   \n",
       "10058  10115  1709.97     Andrew Garnham     AUS 1960-02-06                9   \n",
       "10059  10115  1709.97  Aleksandr Burtsev     BLR 1965-02-13                4   \n",
       "10060  10115  1709.97    Junpei Kanisawa     JPN 1995-12-01              4r4   \n",
       "\n",
       "                 City        Date Legal Note   Sex  Event  \\\n",
       "0            Valencia  2020-10-07     Y  NaN  Male  10000   \n",
       "1           Ad-Dawhah  2019-10-06     Y  NaN  Male  10000   \n",
       "2              London  2017-08-04     Y  NaN  Male  10000   \n",
       "3      Rio de Janeiro  2016-08-13     Y  NaN  Male  10000   \n",
       "4          Gold Coast  2018-04-13     Y  NaN  Male  10000   \n",
       "...               ...         ...   ...  ...   ...    ...   \n",
       "10056       Barakaldo  1997-04-05     Y  NaN  Male  10000   \n",
       "10057       Palo Alto  2008-05-04     Y  NaN  Male  10000   \n",
       "10058       Melbourne  1986-12-18     Y  NaN  Male  10000   \n",
       "10059          Moskva  1990-06-09     Y  NaN  Male  10000   \n",
       "10060           Tokyo  2021-10-24     Y  NaN  Male  10000   \n",
       "\n",
       "       All Conditions Rank Age at Time of Race  \\\n",
       "0                      1.0                  24   \n",
       "1                     39.0                  23   \n",
       "2                     56.0                  20   \n",
       "3                    292.0                  19   \n",
       "4                    478.0                  21   \n",
       "...                    ...                 ...   \n",
       "10056              10048.0                  27   \n",
       "10057              10053.0                  28   \n",
       "10058              10055.0                  26   \n",
       "10059              10055.0                  25   \n",
       "10060              10055.0                  25   \n",
       "\n",
       "                                 competition_id  \n",
       "0      0422bfe2cdbecddf856ee41f164e8bf3bc33f38f  \n",
       "1      39bbc84ed11efeb5bdf814278371fedc2cef5941  \n",
       "2      e4ac5ae5143127a878c03d4999da472502d7eed4  \n",
       "3      db1932a108766537b9222525868da13b72e1596f  \n",
       "4      ee749a0b81a3cdfbbd98574af92138f0f7241373  \n",
       "...                                         ...  \n",
       "10056  d505173d07a70fd35ebd17a2f09daa959e071dde  \n",
       "10057  19e3896b4768cbf1e18a4fc70a61e70c4dbefab1  \n",
       "10058  334cb4c6aac64fbfe1236661e65a79fe96e672da  \n",
       "10059  162f22b38cf055e4619f23c494e3358a7ee96ff2  \n",
       "10060  e1fd79471d342dea26e83901aa715a098075500d  \n",
       "\n",
       "[10061 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_10000m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AthleticsDataScraper_w:\n",
    "    def __init__(self):\n",
    "        self.base_url = 'https://www.alltime-athletics.com/'\n",
    "    \n",
    "    def generate_url(self, event, is_legal):\n",
    "        # Handle special cases with different URL patterns\n",
    "        special_cases = {\n",
    "            '100m' : ('w_100ok.htm', 'w_100no.htm'),\n",
    "            'trip' : ('wtripleok.htm', 'wtripleno.htm'),\n",
    "            'long' : ('wlongok.htm', 'wlongno.htm'),\n",
    "            '100h' : ('w_100hok.htm', 'w_100hno.htm'),\n",
    "            'pole' : ('wpoleok.htm','wpoleno.htm'),\n",
    "            'shot' : ('wshotok.htm','wshotno.htm'),\n",
    "            'disc' : ('wdiscok.htm','wdiscno.htm'),\n",
    "            'jave' : ('wjaveok.htm','wjaveno.htm'),\n",
    "            'hamm' : ('whammok.htm','whammno.htm'),\n",
    "            'hept' : ('whepaok.htm','wheptno.htm'),\n",
    "            '60m'  :   ('w60mok.htm','w60mno.htm'),\n",
    "            '800m' :   ('w_800ok.htm','w_800no.htm'),\n",
    "            '1500m': ('w_1500ok.htm','w_1500no.htm'),\n",
    "            '5000m':   ('w_5000ok.htm','w_5000no.htm'),\n",
    "            '10000':   ('w_10kok.htm','w_10kno.htm')\n",
    "            # Add more special cases here if needed\n",
    "        }\n",
    "        if event in special_cases:\n",
    "            legal_suffix, illegal_suffix = special_cases[event]\n",
    "            suffix = legal_suffix if is_legal else illegal_suffix\n",
    "        else:\n",
    "            suffix = f\"w_{event}{'ok' if is_legal else 'no'}.htm\"\n",
    "        \n",
    "        return f\"{self.base_url}{suffix}\"\n",
    "    \n",
    "    def fetch_data(self, event, is_legal):\n",
    "        url = self.generate_url(event, is_legal)\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        pre_tag = soup.find('pre')\n",
    "        table_text = pre_tag.get_text()\n",
    "        rows = table_text.split('\\n')\n",
    "\n",
    "        def process_row(row):\n",
    "            parts = re.split(r'\\s{2,}', row)\n",
    "            return [part.strip() for part in parts]\n",
    "\n",
    "        data = []\n",
    "        max_length = 0\n",
    "        for row in rows:\n",
    "            if row.strip():\n",
    "                processed_row = process_row(row)\n",
    "                data.append(processed_row)\n",
    "                max_length = max(max_length, len(processed_row))\n",
    "\n",
    "        # Define column names based on the maximum row length\n",
    "        if max_length == 10:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\",\n",
    "                            \"Wind\", \"Name\", \"Country\", \n",
    "                            \"DOB\", \"Position_in_race\",\n",
    "                            \"City\", \"Date\"]\n",
    "        else:\n",
    "            column_names = [\"Test\", \"Rank\", \"Time\",\n",
    "                            \"Name\", \"Country\", \"DOB\", \n",
    "                            \"Position_in_race\", \n",
    "                            \"City\", \"Date\"]\n",
    "\n",
    "        df = pd.DataFrame(data, columns=column_names[:max_length])\n",
    "        df.drop('Test', inplace=True, axis=1, errors='ignore')\n",
    "        df['Legal'] = 'Y' if is_legal else 'N'\n",
    "        has_wind = 'Wind' in df.columns\n",
    "        return df, has_wind\n",
    "    \n",
    "    def convert_mmss_to_seconds(self, time_str):\n",
    "        parts = time_str.split(':')\n",
    "        if len(parts) == 2:\n",
    "            minutes = int(parts[0])\n",
    "            seconds = float(parts[1])\n",
    "            return minutes * 60 + seconds\n",
    "        else:\n",
    "            return np.nan\n",
    "        \n",
    "    def add_all_conditions_rank(self, df, event):\n",
    "        if re.search(r'\\d', event):\n",
    "            # This is a race event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(method='min')\n",
    "        else:\n",
    "            # This is a field event\n",
    "            df['All Conditions Rank'] = df['Time'].rank(ascending=False, method='min')\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def add_age_at_time_of_race(self, df):\n",
    "        # Convert DOB and Date columns to datetime with the correct format\n",
    "        df['DOB']  = pd.to_datetime(df['DOB'], format='%d.%m.%Y', errors='coerce')\n",
    "        df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y', errors='coerce')\n",
    "    \n",
    "        # Correct misinterpreted dates\n",
    "        df['DOB'] = df['DOB'].apply(lambda x: x if pd.isnull(x) or x.year < 2023 else pd.Timestamp(year=x.year - 100, month=x.month, day=x.day))\n",
    "    \n",
    "        # Calculate age at the time of race\n",
    "        df['Age at Time of Race'] = df.apply(lambda row: row['Date'].year - row['DOB'].year - \n",
    "                                             ((row['Date'].month, row['Date'].day) < (row['DOB'].month, row['DOB'].day)) if pd.notnull(row['DOB']) else pd.NA, axis=1)\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    def add_competition_id(self, df):\n",
    "        # Ensure 'Date' is formatted correctly\n",
    "        df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Create a concatenated string of Date and City\n",
    "        df['competition_id'] = df.apply(lambda row: f\"{row['Date']}_{row['City']}\", axis=1)\n",
    "\n",
    "        # Hash the concatenated string to create a unique ID\n",
    "        df['competition_id'] = df['competition_id'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def fill_mode_dob(self, df):\n",
    "        # Calculate mode DOB for each athlete (Name)\n",
    "        mode_dob = df.groupby('Name')['DOB'].agg(lambda x: x.mode().iat[0] if not x.mode().empty else np.nan).reset_index()\n",
    "        \n",
    "        # Merge mode DOB back into original DataFrame\n",
    "        df = df.merge(mode_dob, on='Name', suffixes=('', '_mode'))\n",
    "        \n",
    "        # Replace DOB with mode DOB where DOB is missing or different from mode DOB\n",
    "        df['DOB'] = df.apply(lambda row: row['DOB_mode'] if pd.isnull(row['DOB']) or row['DOB'] != row['DOB_mode'] else row['DOB'], axis=1)\n",
    "        \n",
    "        # Drop temporary columns\n",
    "        df.drop(columns=['DOB_mode'], inplace=True)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    \n",
    "\n",
    "    def get_combined_data(self, event):\n",
    "        df_legal, has_wind = self.fetch_data(event, True)\n",
    "\n",
    "        if has_wind:\n",
    "            df_illegal, _ = self.fetch_data(event, False)\n",
    "            df_combined   = pd.concat([df_legal, df_illegal], ignore_index=True)\n",
    "        else:\n",
    "            df_combined   = df_legal\n",
    "\n",
    "        df_combined.dropna(inplace=True)\n",
    "        df_combined['Date'] = pd.to_datetime(df_combined['Date'], format='%d.%m.%Y',errors='coerce')\n",
    "        df_combined['DOB']  = pd.to_datetime(df_combined['DOB'], format='%d.%m.%y', errors='coerce')\n",
    "        df_combined         = self.fill_mode_dob(df_combined)\n",
    "\n",
    "        # Extract any letters and '#' from the 'Time' column and put them into a new 'Note' column\n",
    "        df_combined['Note'] = df_combined['Time'].str.extract(r'([a-zA-Z#*@+´]+)', expand=False)\n",
    "        # Remove the letters and '#' from the 'Time' column\n",
    "        df_combined['Time'] = df_combined['Time'].str.replace(r'[a-zA-Z#*@+´]', '', regex=True)\n",
    "        if event in ['800','1500', '5000', '10000']:\n",
    "            df_combined['Time'] = df_combined['Time'].apply(self.convert_mmss_to_seconds)\n",
    "        df_combined['Time'] = df_combined['Time'].astype('float')\n",
    "        df_combined = self.add_all_conditions_rank(df_combined, event)\n",
    "\n",
    "        df_combined.loc[df_combined['Legal'] == 'N', 'Rank'] = pd.NA\n",
    "        df_combined          = self.add_age_at_time_of_race(df_combined)\n",
    "        df_combined['Sex']   = 'Female'\n",
    "        df_combined['Event'] = event\n",
    "        df_combined      = self.add_competition_id(df_combined)\n",
    "        return df_combined\n",
    "\n",
    "\n",
    "scraper = AthleticsDataScraper_w()\n",
    "df_200m_w   = scraper.get_combined_data('200')\n",
    "df_100m_w   = scraper.get_combined_data('100m')\n",
    "df_400m_w   = scraper.get_combined_data('400')\n",
    "df_long_w   = scraper.get_combined_data('long')\n",
    "df_trip_w   = scraper.get_combined_data('trip')\n",
    "df_100h_w   = scraper.get_combined_data('100h')\n",
    "df_400h_w   = scraper.get_combined_data('400h')\n",
    "df_pole_w   = scraper.get_combined_data('pole')\n",
    "df_shot_w   = scraper.get_combined_data('shot')\n",
    "df_disc_w   = scraper.get_combined_data('disc')\n",
    "df_jave_w   = scraper.get_combined_data('jave')\n",
    "df_hamm_w   = scraper.get_combined_data('hamm')\n",
    "df_hept_w   = scraper.get_combined_data('hept')\n",
    "df_60m_w    = scraper.get_combined_data('60m')\n",
    "df_300m_w   = scraper.get_combined_data('300')\n",
    "df_800m_w   = scraper.get_combined_data('800')\n",
    "df_5000m_w  = scraper.get_combined_data('5000')\n",
    "df_10000m_w = scraper.get_combined_data('10000')\n",
    "df_1500m_w  = scraper.get_combined_data('1500')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_women = [df_200m_w, df_100m_w, df_400m_w,\n",
    "              df_long_w, df_trip_w, df_100h_w, \n",
    "              df_400h_w, df_pole_w, df_shot_w, \n",
    "              df_disc_w, df_jave_w, df_hamm_w, \n",
    "              df_hept_w, df_60m_w, df_300m_w,\n",
    "              df_1500m_w,df_800m_w, df_10000m_w,\n",
    "              df_5000m_w]\n",
    "\n",
    "combined_women = pd.concat(dfs_women, ignore_index=True)\n",
    "\n",
    "# Combine all men's dataframes\n",
    "dfs_men   = [df_200m, df_100m, df_400m,\n",
    "             df_long, df_trip, df_110h,\n",
    "             df_400h, df_pole, df_shot,\n",
    "             df_disc, df_jave, df_hamm,\n",
    "             df_deca, df_60m, df_300m,\n",
    "             df_1500m, df_5000m, df_10000m,\n",
    "             df_800m]\n",
    "combined_men = pd.concat(dfs_men, ignore_index=True)\n",
    "\n",
    "# Ensure the 'Wind' column is present in all dataframes\n",
    "if 'Wind' not in combined_women.columns:\n",
    "    combined_women['Wind'] = pd.NA\n",
    "if 'Wind' not in combined_men.columns:\n",
    "    combined_men['Wind'] = pd.NA\n",
    "\n",
    "combined_all['Track/Field'] = combined_all['Event'].apply(lambda x: 'Track' if any(char.isdigit() for char in x) else 'Field')\n",
    "\n",
    "# Combine women's and men's dataframes\n",
    "combined_all = pd.concat([combined_women, combined_men], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500     13818\n",
       "5000     13656\n",
       "10000    12528\n",
       "800      10665\n",
       "110h     10330\n",
       "100m     10117\n",
       "200       8392\n",
       "400       8324\n",
       "pole      7826\n",
       "hamm      7685\n",
       "400h      6992\n",
       "60m       6157\n",
       "shot      4303\n",
       "disc      3985\n",
       "long      3370\n",
       "jave      3350\n",
       "trip      3152\n",
       "deca      2737\n",
       "100h      2420\n",
       "hept      2315\n",
       "300        864\n",
       "Name: Event, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_all.Event.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
